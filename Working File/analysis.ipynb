{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id             user_name              user_location  \\\n",
      "0  1340539111971516416            Rachel Roh  La Crescenta-Montrose, CA   \n",
      "1  1338158543359250433           Albert Fong          San Francisco, CA   \n",
      "2  1337858199140118533              eliüá±üáπüá™üá∫üëå                   Your Bed   \n",
      "3  1337855739918835717         Charles Adler     Vancouver, BC - Canada   \n",
      "4  1337854064604966912  Citizen News Channel                        NaN   \n",
      "\n",
      "                                    user_description         user_created  \\\n",
      "0  Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
      "1  Marketing dude, tech geek, heavy metal & '80s ...  2009-09-21 15:27:30   \n",
      "2                                     heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
      "3  Hosting \"CharlesAdlerTonight\" Global News Radi...  2008-09-10 11:28:53   \n",
      "4  Citizen News Channel bringing you an alternati...  2020-04-23 17:58:42   \n",
      "\n",
      "   user_followers  user_friends  user_favourites  user_verified  \\\n",
      "0             405          1692             3247          False   \n",
      "1             834           666              178          False   \n",
      "2              10            88              155          False   \n",
      "3           49165          3933            21853           True   \n",
      "4             152           580             1473          False   \n",
      "\n",
      "                  date                                               text  \\\n",
      "0  2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
      "1  2020-12-13 16:27:13  While the world has been on the wrong side of ...   \n",
      "2  2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
      "3  2020-12-12 20:23:59  Facts are immutable, Senator, even when you're...   \n",
      "4  2020-12-12 20:17:19  Explain to me again why we need a vaccine @Bor...   \n",
      "\n",
      "                                            hashtags               source  \\\n",
      "0                                 ['PfizerBioNTech']  Twitter for Android   \n",
      "1                                                NaN      Twitter Web App   \n",
      "2  ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
      "3                                                NaN      Twitter Web App   \n",
      "4     ['whereareallthesickpeople', 'PfizerBioNTech']   Twitter for iPhone   \n",
      "\n",
      "   retweets  favorites  is_retweet  \n",
      "0         0          0       False  \n",
      "1         1          1       False  \n",
      "2         0          0       False  \n",
      "3       446       2129       False  \n",
      "4         0          0       False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "data = pd.read_csv(\"vaccination_tweets.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "user_name              0\n",
       "user_location       1630\n",
       "user_description     506\n",
       "user_created           0\n",
       "user_followers         0\n",
       "user_friends           0\n",
       "user_favourites        0\n",
       "user_verified          0\n",
       "date                   0\n",
       "text                   0\n",
       "hashtags            1949\n",
       "source                 1\n",
       "retweets               0\n",
       "favorites              0\n",
       "is_retweet             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id  user_followers   user_friends  user_favourites  \\\n",
      "count  4.749000e+03    4.749000e+03    4749.000000      4749.000000   \n",
      "mean   1.355333e+18    5.069683e+04    1341.396926     14523.124447   \n",
      "std    1.280104e+16    3.545440e+05    3453.847283     36379.651961   \n",
      "min    1.337728e+18    0.000000e+00       0.000000         0.000000   \n",
      "25%    1.344929e+18    1.740000e+02     215.000000       497.000000   \n",
      "50%    1.352030e+18    6.480000e+02     549.000000      2713.000000   \n",
      "75%    1.364940e+18    2.728000e+03    1419.000000     12258.000000   \n",
      "max    1.384788e+18    1.371493e+07  103226.000000    854011.000000   \n",
      "\n",
      "          retweets    favorites  \n",
      "count  4749.000000  4749.000000  \n",
      "mean      1.545378     9.385555  \n",
      "std      13.395572    55.280915  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     0.000000  \n",
      "50%       0.000000     1.000000  \n",
      "75%       1.000000     5.000000  \n",
      "max     678.000000  1979.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vidus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "data[\"text\"] = data[\"text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4169\n",
       "True      580\n",
       "Name: user_verified, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"user_verified\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\vidus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  Positive  Negative  \\\n",
      "0   folk said daikon past could treat cytokin stor...     0.252     0.000   \n",
      "2   coronavirus sputnikv astrazeneca pfizerbiontec...     0.000     0.000   \n",
      "6   bit sad claim fame success vaccin patriot comp...     0.353     0.166   \n",
      "9   covidvaccin state start get  monday us say pak...     0.000     0.000   \n",
      "10  death close  mark million peopl wait pfizerbio...     0.000     0.302   \n",
      "\n",
      "    Neutral  \n",
      "0     0.748  \n",
      "2     1.000  \n",
      "6     0.481  \n",
      "9     1.000  \n",
      "10    0.698  \n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"text\"]]\n",
    "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"text\"]]\n",
    "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"text\"]]\n",
    "data = data[[\"text\", \"Positive\", \"Negative\", \"Neutral\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral sentiment \n"
     ]
    }
   ],
   "source": [
    "x = sum(data[\"Positive\"])\n",
    "y = sum(data[\"Negative\"])\n",
    "z = sum(data[\"Neutral\"])\n",
    "\n",
    "def sentiment_score(a, b, c):\n",
    "    if (a>b) and (a>c):\n",
    "        print(\"Positive sentiment \")\n",
    "    elif (b>a) and (b>c):\n",
    "        print(\"Negative sentiment \")\n",
    "    else:\n",
    "        print(\"Neutral sentiment \")\n",
    "sentiment_score(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  417.81600000000003\n",
      "Negative:  188.81200000000024\n",
      "Neutral:  4142.3750000000055\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive: \", x)\n",
    "print(\"Negative: \", y)\n",
    "print(\"Neutral: \", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
